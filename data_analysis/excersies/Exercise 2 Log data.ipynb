{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Analysing log data\n",
    "\n",
    "The aim of this excersies is to analyse data from the user logs generated by the Meerkat system. \n",
    "\n",
    "Every time a page is loaded or the api is called, the actions are logged in a database. The data gathered looks like this: \n",
    "\n",
    "Metadata:\n",
    "\n",
    "`\n",
    "timestamp - time of event, defined at the client as the logging request is sent\n",
    "type - Type of event:\n",
    "\tUser-activity - user prompted activity in front end\n",
    "\tBatch-job - scheduled batch job\n",
    "\tAdmin - administrative activity\n",
    "source - deployment ID\n",
    "source_type - frontend/api/abacus/auth etc: Module that is performing the logging\n",
    "implementation - country or organization name\n",
    "Event Data (JSON): \n",
    "    User-activity: \n",
    "        {\n",
    "            â€œpath\": <relative path>, \n",
    "            \"role\": <user roles>,\n",
    "            \"user\": <user account>, \n",
    "            \"base_url\": <accessed url>, \n",
    "            \"full_url\": <full accessed url>, \n",
    "            \"request_time\": <time spent to deliver request response>\n",
    "         }\n",
    "`\n",
    "\n",
    "The main questions we want to explore are the following: \n",
    "\n",
    "* Who are the most active users\n",
    "* What pages are they visiting\n",
    "* Look at the request time. Which urls take the most time, is there large variability in the request time\n",
    "* What time of day are people accessing the site\n",
    "\n",
    "\n",
    "This data can be explored in two ways. The first following this tutorial is using the python pandas package. The second is to explore this data using SQL. Ask a demonstrator to help you get started with an SQL session to access this data. \n",
    "\n",
    "This notebook contains some help to get the log data into pandas then you can explore the data on your own to aser the questions above. If you want some ideas of the capabilities of pandas you can look at this resource: https://pandas.pydata.org/pandas-docs/stable/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "%matplotlib notebook\n",
    "engine = sqlalchemy.create_engine(\"postgresql+psycopg2://postgres:postgres@localhost/event_db\")\n",
    "data = pd.read_sql_query(\"SELECT * from log\", engine)\n",
    "data = pd.concat([data, data[\"event_data\"].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now explore the log data yourself\n",
    "\n",
    "# Useful pandas functions are groupby, value_counts and various aggregation functions like mean, max, min etc. \n",
    "\n",
    "# See the solutions to this excersie for some examples of analysis you can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
